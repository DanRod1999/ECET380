# -*- coding: utf-8 -*-
"""testfunc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15PdMu4E9sMXbUln9nMaBjV59dQWPA86X
"""

import tensorflow.compat.v2 as tf
import tensorflow_datasets as tfds
from tensorflow import keras
import tensorflow_addons as tfa
import seaborn as sns
import tensorflow_hub as hub
import numpy as np
import pandas as pd
import os

import tensorflow_datasets as tfds
datasets, info = tfds.load("imdb_reviews", as_supervised=True, with_info=True)
def preprocess(X_batch, y_batch):
  X_batch = tf.strings.substr(X_batch, 0, 300)
  X_batch = tf.strings.regex_replace(X_batch, rb"<br\s*/?>", b" ")
  X_batch = tf.strings.regex_replace(X_batch, b"[^a-zA-Z']", b" ")
  X_batch = tf.strings.split(X_batch)
  return X_batch.to_tensor(default_value=b"<pad>"), y_batch
from collections import Counter
vocabulary = Counter()
for X_batch, y_batch in datasets["train"].batch(32).map(preprocess):
  for review in X_batch:
    vocabulary.update(list(review.numpy()))
    vocab_size = 10000
    truncated_vocabulary = [
word for word, count in vocabulary.most_common()[:vocab_size]]

words = tf.constant(truncated_vocabulary)
word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)
vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)
num_oov_buckets = 1000
table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)



def encode_words(X_batch, y_batch):
  return table.lookup(X_batch), y_batch

def run_model(raw_data):
  data_set = raw_data["test"].batch(32).map(preprocess)

  #Import newly made model
  path = os.path.join(".", "imdbModel.h5")
  model = keras.models.load_model(path)
  data_set = data_set.map(encode_words).prefetch(1)

  predictions = model.predict(data_set)
  results = [[0 for x in range(2)] for y in range(len(predictions))]

  for i,data in enumerate(predictions):
    results[i][0] = data[0]
    results[i][1] = 1- data[0]

  return results

run_model(datasets)



